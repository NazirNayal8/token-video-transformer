{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "import time\n",
    "import pytorchvideo\n",
    "import torchvision\n",
    "import wandb\n",
    "from pytorchvideo import transforms as video_transforms\n",
    "from torchvision import transforms as vision_transforms\n",
    "from data.ssv2 import SSV2Dataset\n",
    "from models.video_transformer import DividedVideoTransformer\n",
    "from collections import namedtuple\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torch.optim import Adam, SGD\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_seed(seed):\n",
    "    \"\"\"Set seed\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "\n",
    "def store_params(content, name):\n",
    "    f = open(f'params/{name}.pkl','wb')\n",
    "    pickle.dump(content, f)\n",
    "    f.close()\n",
    "\n",
    "def load_params(name):\n",
    "    fl = open(f'params/{name}.pkl', \"rb\")\n",
    "    loaded = pickle.load(fl)\n",
    "    return loaded\n",
    "\n",
    "def store_model(model, name):\n",
    "    torch.save(model.state_dict(), f'./trained_models/{name}.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Filtering Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_highest_class(upper_limit):\n",
    "\n",
    "    def filter_num(data, upper_limit=upper_limit):\n",
    "        result = []\n",
    "        for d in data:\n",
    "            if d['label'] < upper_limit:\n",
    "                    result.append(d)\n",
    "    \n",
    "        return result\n",
    "    \n",
    "    return filter_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name = 'video_tokenizer'\n",
    "random_seed(8)\n",
    "cores = 18\n",
    "num_classes = 20\n",
    "input_dim = 224\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_mean = [0.5, 0.5, 0.5]\n",
    "frames_std = [0.5, 0.5, 0.5]\n",
    "transforms = vision_transforms.Compose([\n",
    "    vision_transforms.ToTensor(),\n",
    "    vision_transforms.Resize((224, 224)),\n",
    "    vision_transforms.Normalize(mean=frames_mean, std=frames_std)\n",
    "])\n",
    "\n",
    "train_dataset = SSV2Dataset(mode='train', num_samples=10, transforms=transforms,\n",
    "                            filter_by_labels=filter_by_highest_class(num_classes))\n",
    "valid_dataset = SSV2Dataset(mode='valid', num_samples=10, transforms=transforms,\n",
    "                            filter_by_labels=filter_by_highest_class(num_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_valid_num = len(valid_dataset)\n",
    "total_train_num = len(train_dataset)\n",
    "valid_num = int(0.5 * total_valid_num)\n",
    "\n",
    "valid_mask = list(range(valid_num))\n",
    "test_mask = list(range(valid_num, total_valid_num))\n",
    "\n",
    "valid_loader = DataLoader(Subset(valid_dataset, valid_mask), batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(Subset(valid_dataset, test_mask), batch_size=batch_size, shuffle=True)\n",
    "\n",
    "small_train_mask = random.sample(range(total_train_num), 1200)\n",
    "medium_train_mask = random.sample(range(total_train_num), 5000)\n",
    "small_valid_mask = random.sample(range(total_valid_num), 200)\n",
    "\n",
    "small_train_loader = DataLoader(Subset(train_dataset, list(small_train_mask)), batch_size=batch_size, \n",
    "                                shuffle=True, num_workers=2)\n",
    "small_valid_loader = DataLoader(Subset(valid_dataset, list(small_valid_mask)), batch_size=batch_size, \n",
    "                                shuffle=True, num_workers=2)\n",
    "\n",
    "medium_loader = DataLoader(Subset(train_dataset, list(medium_train_mask)), batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loaders(config, valid_test_split=0.5):\n",
    "    \n",
    "    frames_mean = [0.5, 0.5, 0.5]\n",
    "    frames_std = [0.5, 0.5, 0.5]\n",
    "    transforms = vision_transforms.Compose([\n",
    "        vision_transforms.ToTensor(),\n",
    "        vision_transforms.Resize((224, 224)),\n",
    "        vision_transforms.Normalize(mean=frames_mean, std=frames_std)\n",
    "    ])\n",
    "    \n",
    "    train_dataset = SSV2Dataset(mode='train', num_samples=config.num_samples, transforms=transforms,\n",
    "                            filter_by_labels=filter_by_highest_class(num_classes))\n",
    "    valid_dataset = SSV2Dataset(mode='valid', num_samples=config.num_samples, transforms=transforms,\n",
    "                            filter_by_labels=filter_by_highest_class(num_classes))\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True, \n",
    "                              num_workers=config.cores)\n",
    "    \n",
    "    total_valid_num = len(valid_dataset)\n",
    "    total_train_num = len(train_dataset)\n",
    "    valid_num = int(valid_test_split * total_valid_num)\n",
    "\n",
    "    valid_mask = list(range(valid_num))\n",
    "    test_mask = list(range(valid_num, total_valid_num))\n",
    "\n",
    "    valid_loader = DataLoader(Subset(valid_dataset, valid_mask), batch_size=config.batch_size, \n",
    "                              shuffle=True, num_workers=config.cores)\n",
    "    test_loader = DataLoader(Subset(valid_dataset, test_mask), batch_size=config.batch_size, \n",
    "                             shuffle=True, num_workers=config.cores)\n",
    "\n",
    "    return train_loader, valid_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21127, 3427)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset), len(valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model: nn.Module, data_loader: DataLoader, device: torch.device, comment: str = \"\"):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    total_samples = len(data_loader.dataset)\n",
    "    correct_samples = 0\n",
    "    total_loss = 0\n",
    "    loss_history = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in tqdm(data_loader):\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "            \n",
    "            output = F.log_softmax(model(data), dim=1)\n",
    "            loss = F.nll_loss(output, target, reduction='sum')\n",
    "            _, pred = torch.max(output, dim=1)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            correct_samples += pred.eq(target).sum()\n",
    "    \n",
    "    avg_loss = total_loss / total_samples\n",
    "    \n",
    "    accuracy = 100.0 * correct_samples / total_samples\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    \n",
    "    universal_id = random.randint(1, 10000000)\n",
    "    \n",
    "    if mode == 'wandb':\n",
    "        wandb.init(config=config_defaults)\n",
    "        config = wandb.config\n",
    "        wandb.log({'universal_id':universal_id})\n",
    "    else:\n",
    "        config = namedtuple(\"Config\", config_defaults.keys())(*config_defaults.values())\n",
    "        \n",
    "    model = DividedVideoTransformer(\n",
    "        spatial_dim=config.spatial_dim,\n",
    "        temporal_dim=config.temporal_dim,\n",
    "        token_dim=config.token_dim,\n",
    "        tokenizer_type=config.tokenizer_type,\n",
    "        backbone_type=config.backbone_type,\n",
    "        pretrained_backbone=config.pretrained_backbone,\n",
    "        num_classes=config.num_classes,\n",
    "        transformer_layers=config.transformer_layers,\n",
    "        num_heads=config.num_heads,\n",
    "        feedforward_dim=config.feedforward_dim,\n",
    "        dropout=config.dropout,\n",
    "        activation=config.activation\n",
    "    )\n",
    "    \n",
    "    gpu_ids = [i for i in range(int(torch.cuda.device_count()))]\n",
    "    model = nn.DataParallel(model.to(device), device_ids=gpu_ids)\n",
    "    \n",
    "    if config.optimizer == 'adam':\n",
    "        optimizer = Adam(model.parameters(), lr=config.learning_rate, weight_decay=config.weight_decay)\n",
    "    else:\n",
    "        optimizer = SGD(model.parameters(), lr=config.learning_rate, \n",
    "                              weight_decay=config.weight_decay, momentum=0.9)\n",
    "    \n",
    "    lr_scheduler = StepLR(optimizer, step_size=config.decay_step, gamma=config.decay_gamma)\n",
    "    \n",
    "    # prepare data\n",
    "    train_loader, valid_loader, test_loader = get_loaders(config)\n",
    "    \n",
    "    full_start = time.time()\n",
    "    for epoch in tqdm(range(config.epochs), desc='Epochs'):\n",
    "        model.train()\n",
    "        model.to(device)\n",
    "        print(f\"Starting Epoch {epoch}\")\n",
    "        \n",
    "        total_loss = 0\n",
    "        epoch_time = time.time()\n",
    "        for j, (data, label) in enumerate(tqdm(train_loader, desc='Training Iteration')):\n",
    "            \n",
    "            data, label = data.to(device), label.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = F.log_softmax(model(data), dim=1)\n",
    "            loss = F.nll_loss(output, label)\n",
    "            loss.backward()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if mode == 'wandb':\n",
    "                wandb.log({'batch_loss': loss.item()})\n",
    "    \n",
    "        print(f\"Finished Epoch {epoch}\")\n",
    "        lr_scheduler.step()\n",
    "        store_model(model.module, f'ssv2/divided_{universal_id}.pth')\n",
    "        \n",
    "        valid_accuracy = evaluate(model, valid_loader, device)\n",
    "        train_accuracy = evaluate(model, train_loader, device)\n",
    "        \n",
    "        print(f\"Validation Accuracy: \", valid_accuracy)\n",
    "        print(f\"Training Accuracy: \", train_accuracy)\n",
    "        \n",
    "        if mode == 'wandb':\n",
    "            wandb.log({\n",
    "                'loss': total_loss / config.batch_size,\n",
    "                'valid_accuracy': valid_accuracy,\n",
    "                'train_accuracy': train_accuracy,\n",
    "                'epoch_time': time.time() - epoch_time\n",
    "            })\n",
    "    test_accuracy = evaluate(model, test_loader, device)\n",
    "    if mode == 'wandb':\n",
    "        wandb.log({'test_accuracy': test_accuracy})\n",
    "        wandb.log({'full_run_time': time.time() - full_start})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_defaults = {\n",
    "    'epochs': 15,\n",
    "    'spatial_dim': 8,\n",
    "    'temporal_dim': 4,\n",
    "    'token_dim': 512, \n",
    "    'tokenizer_type': 'late_temporal',\n",
    "    'batch_size': 32,\n",
    "    'learning_rate': 0.001,\n",
    "    'transformer_layers': [0, 1],\n",
    "    'pretrained_backbone': True,\n",
    "    'backbone_type': 'resnet18',\n",
    "    'num_heads': 8,\n",
    "    'feedforward_dim': 512,\n",
    "    'dropout': 0.5,\n",
    "    'optimizer': 'adam',\n",
    "    'weight_decay': 0,\n",
    "    'input_dim': input_dim,\n",
    "    'num_classes': num_classes,\n",
    "    'activation': 'relu',\n",
    "    'cores':18,\n",
    "    'num_samples': 10,\n",
    "    'decay_step': 20,\n",
    "    'decay_gamma': 0.1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "    'method': 'grid', #grid, random\n",
    "    'metric': {\n",
    "      'name': 'valid_accuracy',\n",
    "      'goal': 'maximize'   \n",
    "    },\n",
    "    'parameters': {\n",
    "        'learning_rate': {\n",
    "            'values': [0.001, 0.0001]\n",
    "        },\n",
    "        'spatial_dim': {\n",
    "            'values': [4, 6, 8]\n",
    "        },\n",
    "        'temporal_dim': {\n",
    "            'values': [2, 4, 6]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = 'wandb' # local or wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Sweep "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: ee2o4jyv\n",
      "Sweep URL: https://wandb.ai/nazirnayal98/video_tokenizer/sweeps/ee2o4jyv\n"
     ]
    }
   ],
   "source": [
    "sweep_id = wandb.sweep(sweep_config, project=project_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: e1nb3kvd with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tspatial_dim: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttemporal_dim: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnazirnayal98\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.20<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">floral-sweep-1</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/nazirnayal98/video_tokenizer\" target=\"_blank\">https://wandb.ai/nazirnayal98/video_tokenizer</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/nazirnayal98/video_tokenizer/sweeps/ee2o4jyv\" target=\"_blank\">https://wandb.ai/nazirnayal98/video_tokenizer/sweeps/ee2o4jyv</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/nazirnayal98/video_tokenizer/runs/e1nb3kvd\" target=\"_blank\">https://wandb.ai/nazirnayal98/video_tokenizer/runs/e1nb3kvd</a><br/>\n",
       "                Run data is saved locally in <code>/scratch/users/nnayal17/visual_transformer/token-video-transformer/wandb/run-20210520_031441-e1nb3kvd</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d09b22e9a474b3aae175c5cb1a0f50f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Epochs'), FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ec54f2dd9b1463dbeeef5c1d635f466",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Training Iteration'), FloatProgress(value=0.0, max=661.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.agent(sweep_id, train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nazir_env",
   "language": "python",
   "name": "nazir_env"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
